{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4b7969-0bda-4646-bd11-1f2adc149f95",
   "metadata": {},
   "source": [
    "Detect car in image using YOLOv5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93438e-0a5a-4a8f-bdd6-ca740a2fd385",
   "metadata": {},
   "source": [
    "Using dataset at https://www.kaggle.com/datasets/sshikamaru/car-object-detection. But, the data, specifically the .csv file includes only x,y boundary coordinates of car in each image. \n",
    "But, the YOLO format requires {class_id, center_x, center_y, width, height}. So, the input data has to be converted into YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbf79f6-50a9-4770-82f9-2321b19aa53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "\n",
    "csv_path = r'C:\\Users\\Siddhant\\Documents\\Python\\Project5\\train_solution_bounding_boxes.csv'\n",
    "train_images_dir = r'C:\\Users\\Siddhant\\Documents\\Python\\Project5\\training_images'\n",
    "test_images_dir = r'C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images'\n",
    "output_dir = r'C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset'\n",
    "\n",
    "# Output directories\n",
    "train_images_out = os.path.join(output_dir, 'train/images/')\n",
    "train_labels_out = os.path.join(output_dir, 'train/labels/')\n",
    "val_images_out = os.path.join(output_dir, 'val/images/')\n",
    "val_labels_out = os.path.join(output_dir, 'val/labels/')\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(train_images_out, exist_ok=True)\n",
    "os.makedirs(train_labels_out, exist_ok=True)\n",
    "os.makedirs(val_images_out, exist_ok=True)\n",
    "os.makedirs(val_labels_out, exist_ok=True)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Create YOLO annotations\n",
    "def convert_to_yolo(image_name, xmin, ymin, xmax, ymax, img_width, img_height):\n",
    "    center_x = ((xmin + xmax) / 2) / img_width\n",
    "    center_y = ((ymin + ymax) / 2) / img_height\n",
    "    box_width = (xmax - xmin) / img_width\n",
    "    box_height = (ymax - ymin) / img_height\n",
    "    return f\"0 {center_x} {center_y} {box_width} {box_height}\\n\"\n",
    "\n",
    "# Process each row in the CSV\n",
    "annotations = {}\n",
    "for _, row in df.iterrows():\n",
    "    image_name = row['image']\n",
    "    xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "    \n",
    "    # Load image to get dimensions\n",
    "    image_path = os.path.join(train_images_dir, image_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Image {image_name} not found. Skipping.\")\n",
    "        continue\n",
    "    img_height, img_width, _ = img.shape\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotation = convert_to_yolo(image_name, xmin, ymin, xmax, ymax, img_width, img_height)\n",
    "\n",
    "    # Store annotation\n",
    "    if image_name not in annotations:\n",
    "        annotations[image_name] = []\n",
    "    annotations[image_name].append(yolo_annotation)\n",
    "\n",
    "# Save annotations to .txt files\n",
    "for image_name, yolo_annotations in annotations.items():\n",
    "    txt_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    txt_path = os.path.join(train_labels_out, txt_name)\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.writelines(yolo_annotations)\n",
    "\n",
    "# Split into train and val sets\n",
    "train_files, val_files = train_test_split(list(annotations.keys()), test_size=0.2, random_state=42)\n",
    "\n",
    "# Move images and annotations to train/val folders\n",
    "for image_name in train_files:\n",
    "    shutil.copy(os.path.join(train_images_dir, image_name), os.path.join(train_images_out, image_name))\n",
    "    txt_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    shutil.move(os.path.join(train_labels_out, txt_name), os.path.join(train_labels_out, txt_name))\n",
    "\n",
    "for image_name in val_files:\n",
    "    shutil.copy(os.path.join(train_images_dir, image_name), os.path.join(val_images_out, image_name))\n",
    "    txt_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    shutil.move(os.path.join(train_labels_out, txt_name), os.path.join(val_labels_out, txt_name))\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971f888-7f67-456a-9fe8-f207c22da6a1",
   "metadata": {},
   "source": [
    "Note that the labels diectory will be converted into YOLO formatted .txt files.\n",
    "\n",
    "Now, let us pull YOLOV5, our pretained model for car detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ba8165-0e3c-4234-8ff1-78d20048b9d2",
   "metadata": {},
    "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21564b9a-180f-4ef8-8116-8b68a3113ca6",
   "metadata": {},
   "source": [
    "Now, let us create the .yaml file for YOLO. Under 'yolo5' directory, create config.yaml with below content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacab43e-b50f-4441-80ef-72ebd94503d3",
   "metadata": {},
   "source": [
    "nc: 1\n",
    "\n",
    "names: ['car']\n",
    "\n",
    "train: path_where_kaggledataset_was_downloaded\\dataset\\train\\images\n",
    "\n",
    "val: path_where_kaggledataset_was_downloaded\\dataset\\val\\images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7c321-b565-4fc3-824f-289b9d5784ff",
   "metadata": {},
   "source": [
    "Now, let us train the model.\n",
    "\n",
    "--C:\\Users\\Siddhant\\yolov5\\train.py: This runs the train.py script from the YOLOv5 repository that was downloaded\n",
    "\n",
    "--img 640: Sets the input image size to 640x640 pixels.\n",
    "\n",    
    "--batch 16: Specifies the batch size for training (number of images processed simultaneously).\n",
    "\n",    
    "--epochs 2: Sets the number of training epochs (complete passes through the dataset.\n",
    "\n",
    "Note: epochs 2 is very low and this will affect the number of successful detections. Typical value is 100 for large data sets, while this will improve the successful predictions if\n",
    "car exists in a given image, training time will drastically increase as well.\n",
    "\n",
    "--data C:\\Users\\Siddhant\\yolov5\\config.yaml: Points to the YAML file containing dataset information (like class names and image paths).\n",
    "\n",
    "--weights yolov5s.pt: Uses pre-trained YOLOv5s weights as a starting point for training.\n",
    "\n",    
    "--name car_detection: Assigns a name to the training run, which will be used for the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e20881a-98e2-4043-99d0-da784d1a2ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command 'git fetch origin' timed out after 5 seconds"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=C:\\Users\\Siddhant\\yolov5\\config.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=2, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5\\data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=car_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "YOLOv5  v7.0-397-gde62f93c Python-3.9.10 torch-2.5.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "\n",
      "  0%|          | 0.00/14.1M [00:00<?, ?B/s]\n",
      "  5%|5         | 768k/14.1M [00:00<00:01, 7.07MB/s]\n",
      " 19%|#8        | 2.62M/14.1M [00:00<00:00, 13.4MB/s]\n",
      " 36%|###6      | 5.12M/14.1M [00:00<00:00, 18.8MB/s]\n",
      " 51%|#####1    | 7.25M/14.1M [00:00<00:00, 16.0MB/s]\n",
      " 71%|#######   | 10.0M/14.1M [00:00<00:00, 19.3MB/s]\n",
      " 89%|########8 | 12.5M/14.1M [00:00<00:00, 21.2MB/s]\n",
      "100%|##########| 14.1M/14.1M [00:00<00:00, 19.5MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\train\\labels.cache... 284 images, 0 backgrounds, 0 corrupt: 100%|##########| 284/284 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\train\\labels.cache... 284 images, 0 backgrounds, 0 corrupt: 100%|##########| 284/284 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to yolov5\\runs\\train\\car_detection3\\labels.jpg... \n",
      "C:\\Users\\Siddhant\\yolov5\\train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5\\runs\\train\\car_detection3\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G      0.126    0.03181          0         41        640:   0%|          | 0/18 [00:41<?, ?it/s]\n",
      "        0/1         0G      0.126    0.03181          0         41        640:   6%|5         | 1/18 [00:49<13:58, 49.34s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1259    0.03153          0         39        640:   6%|5         | 1/18 [01:09<13:58, 49.34s/it]\n",
      "        0/1         0G     0.1259    0.03153          0         39        640:  11%|#1        | 2/18 [01:09<08:36, 32.30s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1249    0.03096          0         34        640:  11%|#1        | 2/18 [01:28<08:36, 32.30s/it]\n",
      "        0/1         0G     0.1249    0.03096          0         34        640:  17%|#6        | 3/18 [01:28<06:32, 26.14s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1245     0.0314          0         50        640:  17%|#6        | 3/18 [01:46<06:32, 26.14s/it]\n",
      "        0/1         0G     0.1245     0.0314          0         50        640:  22%|##2       | 4/18 [01:46<05:18, 22.76s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G      0.124    0.03172          0         50        640:  22%|##2       | 4/18 [02:03<05:18, 22.76s/it]\n",
      "        0/1         0G      0.124    0.03172          0         50        640:  28%|##7       | 5/18 [02:03<04:29, 20.76s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1229    0.03157          0         36        640:  28%|##7       | 5/18 [02:19<04:29, 20.76s/it]\n",
      "        0/1         0G     0.1229    0.03157          0         36        640:  33%|###3      | 6/18 [02:19<03:50, 19.22s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1218    0.03187          0         47        640:  33%|###3      | 6/18 [02:35<03:50, 19.22s/it]\n",
      "        0/1         0G     0.1218    0.03187          0         47        640:  39%|###8      | 7/18 [02:35<03:20, 18.25s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1205    0.03182          0         43        640:  39%|###8      | 7/18 [02:51<03:20, 18.25s/it]\n",
      "        0/1         0G     0.1205    0.03182          0         43        640:  44%|####4     | 8/18 [02:51<02:54, 17.43s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G      0.119    0.03163          0         35        640:  44%|####4     | 8/18 [03:07<02:54, 17.43s/it]\n",
      "        0/1         0G      0.119    0.03163          0         35        640:  50%|#####     | 9/18 [03:07<02:34, 17.12s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1177    0.03198          0         51        640:  50%|#####     | 9/18 [03:23<02:34, 17.12s/it]\n",
      "        0/1         0G     0.1177    0.03198          0         51        640:  56%|#####5    | 10/18 [03:23<02:13, 16.74s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1164    0.03208          0         47        640:  56%|#####5    | 10/18 [03:39<02:13, 16.74s/it]\n",
      "        0/1         0G     0.1164    0.03208          0         47        640:  61%|######1   | 11/18 [03:39<01:55, 16.53s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1149    0.03225          0         49        640:  61%|######1   | 11/18 [03:55<01:55, 16.53s/it]\n",
      "        0/1         0G     0.1149    0.03225          0         49        640:  67%|######6   | 12/18 [03:55<01:38, 16.41s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1136    0.03236          0         48        640:  67%|######6   | 12/18 [04:11<01:38, 16.41s/it]\n",
      "        0/1         0G     0.1136    0.03236          0         48        640:  72%|#######2  | 13/18 [04:11<01:21, 16.27s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1123    0.03258          0         54        640:  72%|#######2  | 13/18 [04:28<01:21, 16.27s/it]\n",
      "        0/1         0G     0.1123    0.03258          0         54        640:  78%|#######7  | 14/18 [04:28<01:05, 16.30s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1112     0.0328          0         55        640:  78%|#######7  | 14/18 [04:43<01:05, 16.30s/it]\n",
      "        0/1         0G     0.1112     0.0328          0         55        640:  83%|########3 | 15/18 [04:43<00:48, 16.04s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1098     0.0326          0         37        640:  83%|########3 | 15/18 [04:59<00:48, 16.04s/it]\n",
      "        0/1         0G     0.1098     0.0326          0         37        640:  89%|########8 | 16/18 [04:59<00:31, 15.97s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1083    0.03249          0         38        640:  89%|########8 | 16/18 [05:15<00:31, 15.97s/it]\n",
      "        0/1         0G     0.1083    0.03249          0         38        640:  94%|#########4| 17/18 [05:15<00:15, 15.89s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        0/1         0G     0.1071    0.03225          0         26        640:  94%|#########4| 17/18 [05:27<00:15, 15.89s/it]\n",
      "        0/1         0G     0.1071    0.03225          0         26        640: 100%|##########| 18/18 [05:27<00:00, 14.70s/it]\n",
      "        0/1         0G     0.1071    0.03225          0         26        640: 100%|##########| 18/18 [05:27<00:00, 18.18s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:08<00:17,  8.79s/it]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:16<00:08,  8.36s/it]WARNING  NMS time limit 0.850s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  5.46s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  6.28s/it]\n",
      "                   all         71        119      0.482      0.328      0.286      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08011    0.02803          0         34        640:   0%|          | 0/18 [00:15<?, ?it/s]\n",
      "        1/1         0G    0.08011    0.02803          0         34        640:   6%|5         | 1/18 [00:15<04:21, 15.36s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08096    0.03106          0         49        640:   6%|5         | 1/18 [00:31<04:21, 15.36s/it]\n",
      "        1/1         0G    0.08096    0.03106          0         49        640:  11%|#1        | 2/18 [00:31<04:14, 15.92s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08183    0.03196          0         46        640:  11%|#1        | 2/18 [00:47<04:14, 15.92s/it]\n",
      "        1/1         0G    0.08183    0.03196          0         46        640:  17%|#6        | 3/18 [00:47<03:57, 15.87s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08331    0.03259          0         52        640:  17%|#6        | 3/18 [01:03<03:57, 15.87s/it]\n",
      "        1/1         0G    0.08331    0.03259          0         52        640:  22%|##2       | 4/18 [01:03<03:43, 15.95s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08314    0.03324          0         54        640:  22%|##2       | 4/18 [01:19<03:43, 15.95s/it]\n",
      "        1/1         0G    0.08314    0.03324          0         54        640:  28%|##7       | 5/18 [01:19<03:28, 16.03s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08257    0.03258          0         44        640:  28%|##7       | 5/18 [01:35<03:28, 16.03s/it]\n",
      "        1/1         0G    0.08257    0.03258          0         44        640:  33%|###3      | 6/18 [01:35<03:10, 15.90s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08232     0.0326          0         48        640:  33%|###3      | 6/18 [01:52<03:10, 15.90s/it]\n",
      "        1/1         0G    0.08232     0.0326          0         48        640:  39%|###8      | 7/18 [01:52<03:00, 16.44s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08187    0.03217          0         38        640:  39%|###8      | 7/18 [02:09<03:00, 16.44s/it]\n",
      "        1/1         0G    0.08187    0.03217          0         38        640:  44%|####4     | 8/18 [02:09<02:45, 16.53s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08185     0.0318          0         38        640:  44%|####4     | 8/18 [02:26<02:45, 16.53s/it]\n",
      "        1/1         0G    0.08185     0.0318          0         38        640:  50%|#####     | 9/18 [02:26<02:29, 16.62s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08146    0.03198          0         47        640:  50%|#####     | 9/18 [02:43<02:29, 16.62s/it]\n",
      "        1/1         0G    0.08146    0.03198          0         47        640:  56%|#####5    | 10/18 [02:43<02:13, 16.72s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08142    0.03221          0         51        640:  56%|#####5    | 10/18 [02:59<02:13, 16.72s/it]\n",
      "        1/1         0G    0.08142    0.03221          0         51        640:  61%|######1   | 11/18 [02:59<01:55, 16.48s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08128    0.03211          0         46        640:  61%|######1   | 11/18 [03:15<01:55, 16.48s/it]\n",
      "        1/1         0G    0.08128    0.03211          0         46        640:  67%|######6   | 12/18 [03:15<01:37, 16.33s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08141    0.03171          0         36        640:  67%|######6   | 12/18 [03:30<01:37, 16.33s/it]\n",
      "        1/1         0G    0.08141    0.03171          0         36        640:  72%|#######2  | 13/18 [03:30<01:20, 16.12s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08115     0.0319          0         53        640:  72%|#######2  | 13/18 [03:46<01:20, 16.12s/it]\n",
      "        1/1         0G    0.08115     0.0319          0         53        640:  78%|#######7  | 14/18 [03:46<01:04, 16.08s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08094    0.03196          0         48        640:  78%|#######7  | 14/18 [04:03<01:04, 16.08s/it]\n",
      "        1/1         0G    0.08094    0.03196          0         48        640:  83%|########3 | 15/18 [04:03<00:48, 16.08s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08049    0.03192          0         45        640:  83%|########3 | 15/18 [04:19<00:48, 16.08s/it]\n",
      "        1/1         0G    0.08049    0.03192          0         45        640:  89%|########8 | 16/18 [04:19<00:32, 16.14s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08018    0.03173          0         37        640:  89%|########8 | 16/18 [04:35<00:32, 16.14s/it]\n",
      "        1/1         0G    0.08018    0.03173          0         37        640:  94%|#########4| 17/18 [04:35<00:16, 16.11s/it]C:\\Users\\Siddhant\\yolov5\\train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "\n",
      "        1/1         0G    0.08002    0.03137          0         24        640:  94%|#########4| 17/18 [04:47<00:16, 16.11s/it]\n",
      "        1/1         0G    0.08002    0.03137          0         24        640: 100%|##########| 18/18 [04:47<00:00, 14.86s/it]\n",
      "        1/1         0G    0.08002    0.03137          0         24        640: 100%|##########| 18/18 [04:47<00:00, 15.96s/it]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:08<00:17,  8.53s/it]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:16<00:08,  8.30s/it]WARNING  NMS time limit 0.850s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  5.51s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  6.29s/it]\n",
      "                   all         71        119      0.386      0.433      0.292     0.0773\n",
      "\n",
      "2 epochs completed in 0.181 hours.\n",
      "Optimizer stripped from yolov5\\runs\\train\\car_detection3\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from yolov5\\runs\\train\\car_detection3\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating yolov5\\runs\\train\\car_detection3\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:07<00:15,  7.64s/it]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:15<00:07,  7.83s/it]WARNING  NMS time limit 0.850s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:17<00:00,  5.22s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:17<00:00,  5.91s/it]\n",
      "                   all         71        119      0.467      0.336      0.304       0.11\n",
      "Results saved to \u001b[1myolov5\\runs\\train\\car_detection3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Siddhant\\yolov5\\train.py --img 640 --batch 16 --epochs 2 --data C:\\Users\\Siddhant\\yolov5\\config.yaml --weights yolov5s.pt --name car_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1b57b-8d1b-4fc9-9130-d0b28bc8ad64",
   "metadata": {},
   "source": [
    "Now, let us validate our training. best.pt is where the best results of weights from training is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6da3a0ce-267d-4c1c-8f81-ddce63664127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=C:\\Users\\Siddhant\\yolov5\\config.yaml, weights=['C:\\\\Users\\\\Siddhant\\\\yolov5\\\\runs\\\\train\\\\car_detection3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5\\runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5  v7.0-397-gde62f93c Python-3.9.10 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:09<00:18,  9.29s/it]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:16<00:08,  8.15s/it]WARNING  NMS time limit 0.850s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  5.24s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:18<00:00,  6.14s/it]\n",
      "                   all         71        119      0.471       0.37      0.324      0.112\n",
      "Speed: 1.9ms pre-process, 174.6ms inference, 74.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\val\\exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Siddhant\\yolov5\\val.py --weights C:\\Users\\Siddhant\\yolov5\\runs\\train\\car_detection3/weights/best.pt --data C:\\Users\\Siddhant\\yolov5\\config.yaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f659e38-d049-434b-85b3-57f214538bc8",
   "metadata": {},
   "source": [
    "Not good results. Let us retrain our model with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "553386bb-268e-4dc4-84b0-8ac9e737da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command 'git fetch origin' timed out after 5 seconds"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=C:\\Users\\Siddhant\\yolov5\\config.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5\\data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=car_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "YOLOv5  v7.0-397-gde62f93c Python-3.9.10 torch-2.5.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\train\\labels.cache... 284 images, 0 backgrounds, 0 corrupt: 100%|##########| 284/284 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\train\\labels.cache... 284 images, 0 backgrounds, 0 corrupt: 100%|##########| 284/284 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to yolov5\\runs\\train\\car_detection5\\labels.jpg... \n",
      "C:\\Users\\Siddhant\\yolov5\\train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5\\runs\\train\\car_detection5\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      
      "25 epochs completed in 1.995 hours.\n",
      "Optimizer stripped from yolov5\\runs\\train\\car_detection5\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from yolov5\\runs\\train\\car_detection5\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating yolov5\\runs\\train\\car_detection5\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:04<00:09,  4.93s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:10<00:05,  5.41s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:11<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:11<00:00,  3.96s/it]\n",
      "                   all         71        119      0.958      0.957       0.98      0.633\n",
      "Results saved to \u001b[1myolov5\\runs\\train\\car_detection5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Siddhant\\yolov5\\train.py --img 640 --batch 16 --epochs 25 --data C:\\Users\\Siddhant\\yolov5\\config.yaml --weights yolov5s.pt --name car_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a5cf250-a9c0-44de-aed1-aae0a13e67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=C:\\Users\\Siddhant\\yolov5\\config.yaml, weights=['C:\\\\Users\\\\Siddhant\\\\yolov5\\\\runs\\\\train\\\\car_detection5/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5\\runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5  v7.0-397-gde62f93c Python-3.9.10 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Siddhant\\Documents\\Python\\Project5\\dataset\\val\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|##########| 71/71 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|###3      | 1/3 [00:06<00:13,  6.94s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|######6   | 2/3 [00:12<00:06,  6.22s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:13<00:00,  3.88s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|##########| 3/3 [00:13<00:00,  4.58s/it]\n",
      "                   all         71        119      0.958      0.957       0.98      0.634\n",
      "Speed: 2.0ms pre-process, 174.6ms inference, 1.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\val\\exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Siddhant\\yolov5\\val.py --weights C:\\Users\\Siddhant\\yolov5\\runs\\train\\car_detection5/weights/best.pt --data C:\\Users\\Siddhant\\yolov5\\config.yaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d0010-6c85-40a2-b4f3-c53046e70c92",
   "metadata": {},
   "source": [
    "Much, much better results as observed from val_batchx_pred file. How many labels model is able to detect from val dataset - let us find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e773c76b-7766-428f-8f96-8d513e9d96a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['C:\\\\Users\\\\Siddhant\\\\yolov5\\\\runs\\\\train\\\\car_detection5\\\\weights\\\\best.pt'], source=C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-397-gde62f93c Python-3.9.10 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25100.jpg: 384x640 (no detections), 94.1ms\n",
      "image 2/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25120.jpg: 384x640 (no detections), 94.2ms\n",
      "image 3/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25140.jpg: 384x640 (no detections), 78.6ms\n",
      "image 4/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25160.jpg: 384x640 (no detections), 78.5ms\n",
      "image 5/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25180.jpg: 384x640 (no detections), 78.5ms\n",
      "image 6/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25200.jpg: 384x640 (no detections), 78.9ms\n",
      "image 7/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25220.jpg: 384x640 (no detections), 78.5ms\n",
      "image 8/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25240.jpg: 384x640 (no detections), 94.3ms\n",
      "image 9/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_25260.jpg: 384x640 (no detections), 87.1ms\n",
      "image 10/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26320.jpg: 384x640 (no detections), 79.0ms\n",
      "image 11/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26400.jpg: 384x640 (no detections), 78.8ms\n",
      "image 12/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26420.jpg: 384x640 (no detections), 95.2ms\n",
      "image 13/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26560.jpg: 384x640 1 car, 93.4ms\n",
      "image 14/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26580.jpg: 384x640 1 car, 94.1ms\n",
      "image 15/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26600.jpg: 384x640 2 cars, 82.3ms\n",
      "image 16/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26620.jpg: 384x640 1 car, 94.5ms\n",
      "image 17/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26640.jpg: 384x640 3 cars, 94.4ms\n",
      "image 18/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26660.jpg: 384x640 1 car, 87.6ms\n",
      "image 19/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26680.jpg: 384x640 3 cars, 110.7ms\n",
      "image 20/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26700.jpg: 384x640 2 cars, 79.1ms\n",
      "image 21/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26720.jpg: 384x640 3 cars, 111.4ms\n",
      "image 22/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26740.jpg: 384x640 3 cars, 95.7ms\n",
      "image 23/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26760.jpg: 384x640 3 cars, 74.2ms\n",
      "image 24/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26780.jpg: 384x640 2 cars, 84.5ms\n",
      "image 25/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26800.jpg: 384x640 3 cars, 100.1ms\n",
      "image 26/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26820.jpg: 384x640 2 cars, 94.4ms\n",
      "image 27/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26840.jpg: 384x640 1 car, 96.0ms\n",
      "image 28/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26860.jpg: 384x640 1 car, 88.0ms\n",
      "image 29/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26880.jpg: 384x640 1 car, 109.9ms\n",
      "image 30/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26900.jpg: 384x640 3 cars, 78.7ms\n",
      "image 31/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26920.jpg: 384x640 2 cars, 94.9ms\n",
      "image 32/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26940.jpg: 384x640 2 cars, 93.6ms\n",
      "image 33/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26960.jpg: 384x640 1 car, 94.6ms\n",
      "image 34/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_26980.jpg: 384x640 (no detections), 78.5ms\n",
      "image 35/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27240.jpg: 384x640 1 car, 95.2ms\n",
      "image 36/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27260.jpg: 384x640 (no detections), 79.1ms\n",
      "image 37/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27280.jpg: 384x640 (no detections), 87.0ms\n",
      "image 38/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27300.jpg: 384x640 2 cars, 94.3ms\n",
      "image 39/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27320.jpg: 384x640 2 cars, 110.7ms\n",
      "image 40/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27360.jpg: 384x640 3 cars, 94.6ms\n",
      "image 41/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27380.jpg: 384x640 3 cars, 94.4ms\n",
      "image 42/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27400.jpg: 384x640 3 cars, 78.5ms\n",
      "image 43/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27420.jpg: 384x640 3 cars, 125.3ms\n",
      "image 44/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27440.jpg: 384x640 3 cars, 126.1ms\n",
      "image 45/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27460.jpg: 384x640 3 cars, 109.9ms\n",
      "image 46/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27480.jpg: 384x640 4 cars, 94.6ms\n",
      "image 47/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27500.jpg: 384x640 1 car, 130.3ms\n",
      "image 48/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27520.jpg: 384x640 2 cars, 93.7ms\n",
      "image 49/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27540.jpg: 384x640 2 cars, 94.0ms\n",
      "image 50/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27560.jpg: 384x640 1 car, 95.0ms\n",
      "image 51/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27580.jpg: 384x640 (no detections), 79.0ms\n",
      "image 52/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27600.jpg: 384x640 (no detections), 110.6ms\n",
      "image 53/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27620.jpg: 384x640 1 car, 132.9ms\n",
      "image 54/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27640.jpg: 384x640 1 car, 110.0ms\n",
      "image 55/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27660.jpg: 384x640 (no detections), 110.0ms\n",
      "image 56/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27680.jpg: 384x640 (no detections), 157.7ms\n",
      "image 57/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27700.jpg: 384x640 (no detections), 110.2ms\n",
      "image 58/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27720.jpg: 384x640 (no detections), 110.7ms\n",
      "image 59/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27740.jpg: 384x640 (no detections), 110.1ms\n",
      "image 60/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27760.jpg: 384x640 (no detections), 134.1ms\n",
      "image 61/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27780.jpg: 384x640 (no detections), 126.2ms\n",
      "image 62/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27800.jpg: 384x640 (no detections), 179.2ms\n",
      "image 63/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27820.jpg: 384x640 1 car, 142.5ms\n",
      "image 64/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27840.jpg: 384x640 1 car, 111.3ms\n",
      "image 65/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27860.jpg: 384x640 1 car, 127.0ms\n",
      "image 66/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27880.jpg: 384x640 1 car, 120.1ms\n",
      "image 67/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27900.jpg: 384x640 1 car, 157.4ms\n",
      "image 68/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27920.jpg: 384x640 1 car, 157.7ms\n",
      "image 69/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27940.jpg: 384x640 1 car, 141.6ms\n",
      "image 70/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27960.jpg: 384x640 (no detections), 156.0ms\n",
      "image 71/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_27980.jpg: 384x640 (no detections), 220.3ms\n",
      "image 72/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28000.jpg: 384x640 (no detections), 188.7ms\n",
      "image 73/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28020.jpg: 384x640 (no detections), 173.2ms\n",
      "image 74/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28040.jpg: 384x640 (no detections), 125.8ms\n",
      "image 75/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28060.jpg: 384x640 (no detections), 172.7ms\n",
      "image 76/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28080.jpg: 384x640 (no detections), 139.5ms\n",
      "image 77/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28180.jpg: 384x640 (no detections), 152.3ms\n",
      "image 78/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28260.jpg: 384x640 1 car, 180.6ms\n",
      "image 79/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28320.jpg: 384x640 (no detections), 142.7ms\n",
      "image 80/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28340.jpg: 384x640 (no detections), 141.5ms\n",
      "image 81/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28360.jpg: 384x640 (no detections), 172.7ms\n",
      "image 82/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28380.jpg: 384x640 1 car, 197.5ms\n",
      "image 83/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28420.jpg: 384x640 1 car, 204.7ms\n",
      "image 84/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28440.jpg: 384x640 1 car, 189.2ms\n",
      "image 85/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28460.jpg: 384x640 (no detections), 220.3ms\n",
      "image 86/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28480.jpg: 384x640 (no detections), 172.9ms\n",
      "image 87/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28500.jpg: 384x640 1 car, 170.5ms\n",
      "image 88/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28520.jpg: 384x640 1 car, 176.1ms\n",
      "image 89/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28540.jpg: 384x640 1 car, 189.8ms\n",
      "image 90/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28560.jpg: 384x640 (no detections), 186.8ms\n",
      "image 91/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28580.jpg: 384x640 (no detections), 161.3ms\n",
      "image 92/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28600.jpg: 384x640 (no detections), 156.6ms\n",
      "image 93/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28620.jpg: 384x640 (no detections), 189.5ms\n",
      "image 94/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28640.jpg: 384x640 (no detections), 193.7ms\n",
      "image 95/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28660.jpg: 384x640 (no detections), 207.5ms\n",
      "image 96/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28680.jpg: 384x640 (no detections), 157.0ms\n",
      "image 97/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_28700.jpg: 384x640 (no detections), 188.8ms\n",
      "image 98/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29000.jpg: 384x640 2 cars, 190.3ms\n",
      "image 99/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29020.jpg: 384x640 1 car, 157.0ms\n",
      "image 100/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29040.jpg: 384x640 1 car, 163.4ms\n",
      "image 101/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29060.jpg: 384x640 (no detections), 141.9ms\n",
      "image 102/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29080.jpg: 384x640 (no detections), 158.0ms\n",
      "image 103/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29100.jpg: 384x640 (no detections), 172.5ms\n",
      "image 104/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29400.jpg: 384x640 1 car, 157.6ms\n",
      "image 105/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29420.jpg: 384x640 2 cars, 149.3ms\n",
      "image 106/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29440.jpg: 384x640 2 cars, 140.9ms\n",
      "image 107/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29460.jpg: 384x640 1 car, 157.8ms\n",
      "image 108/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29480.jpg: 384x640 1 car, 141.3ms\n",
      "image 109/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29500.jpg: 384x640 (no detections), 157.7ms\n",
      "image 110/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29520.jpg: 384x640 (no detections), 157.6ms\n",
      "image 111/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29540.jpg: 384x640 2 cars, 148.0ms\n",
      "image 112/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29560.jpg: 384x640 1 car, 127.0ms\n",
      "image 113/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29580.jpg: 384x640 1 car, 148.8ms\n",
      "image 114/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29600.jpg: 384x640 (no detections), 173.3ms\n",
      "image 115/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29620.jpg: 384x640 (no detections), 139.9ms\n",
      "image 116/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29640.jpg: 384x640 (no detections), 130.7ms\n",
      "image 117/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29720.jpg: 384x640 (no detections), 186.9ms\n",
      "image 118/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29740.jpg: 384x640 (no detections), 157.2ms\n",
      "image 119/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29760.jpg: 384x640 1 car, 125.8ms\n",
      "image 120/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29820.jpg: 384x640 1 car, 164.9ms\n",
      "image 121/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29840.jpg: 384x640 1 car, 170.5ms\n",
      "image 122/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29860.jpg: 384x640 (no detections), 228.5ms\n",
      "image 123/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29880.jpg: 384x640 (no detections), 240.0ms\n",
      "image 124/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29900.jpg: 384x640 (no detections), 252.1ms\n",
      "image 125/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_29980.jpg: 384x640 (no detections), 188.7ms\n",
      "image 126/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30000.jpg: 384x640 (no detections), 199.8ms\n",
      "image 127/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30020.jpg: 384x640 (no detections), 202.9ms\n",
      "image 128/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30040.jpg: 384x640 (no detections), 188.5ms\n",
      "image 129/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30120.jpg: 384x640 (no detections), 203.6ms\n",
      "image 130/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30140.jpg: 384x640 (no detections), 167.1ms\n",
      "image 131/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30160.jpg: 384x640 (no detections), 157.1ms\n",
      "image 132/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30180.jpg: 384x640 (no detections), 142.5ms\n",
      "image 133/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30640.jpg: 384x640 1 car, 221.2ms\n",
      "image 134/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30660.jpg: 384x640 (no detections), 221.1ms\n",
      "image 135/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30680.jpg: 384x640 (no detections), 211.0ms\n",
      "image 136/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30700.jpg: 384x640 (no detections), 157.5ms\n",
      "image 137/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30720.jpg: 384x640 (no detections), 173.2ms\n",
      "image 138/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30740.jpg: 384x640 1 car, 141.9ms\n",
      "image 139/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30760.jpg: 384x640 2 cars, 188.7ms\n",
      "image 140/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30820.jpg: 384x640 3 cars, 179.2ms\n",
      "image 141/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30840.jpg: 384x640 2 cars, 136.4ms\n",
      "image 142/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30860.jpg: 384x640 2 cars, 173.9ms\n",
      "image 143/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30920.jpg: 384x640 2 cars, 142.9ms\n",
      "image 144/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_30940.jpg: 384x640 2 cars, 157.6ms\n",
      "image 145/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31020.jpg: 384x640 2 cars, 173.1ms\n",
      "image 146/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31040.jpg: 384x640 3 cars, 116.9ms\n",
      "image 147/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31060.jpg: 384x640 1 car, 173.1ms\n",
      "image 148/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31080.jpg: 384x640 2 cars, 141.3ms\n",
      "image 149/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31100.jpg: 384x640 1 car, 172.6ms\n",
      "image 150/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31120.jpg: 384x640 2 cars, 119.6ms\n",
      "image 151/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31140.jpg: 384x640 1 car, 141.8ms\n",
      "image 152/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31160.jpg: 384x640 1 car, 181.0ms\n",
      "image 153/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31180.jpg: 384x640 (no detections), 173.5ms\n",
      "image 154/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31200.jpg: 384x640 (no detections), 171.6ms\n",
      "image 155/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31260.jpg: 384x640 (no detections), 157.1ms\n",
      "image 156/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31280.jpg: 384x640 (no detections), 152.4ms\n",
      "image 157/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31300.jpg: 384x640 (no detections), 158.1ms\n",
      "image 158/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31360.jpg: 384x640 (no detections), 164.5ms\n",
      "image 159/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31380.jpg: 384x640 (no detections), 190.4ms\n",
      "image 160/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31400.jpg: 384x640 (no detections), 110.5ms\n",
      "image 161/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31420.jpg: 384x640 (no detections), 110.4ms\n",
      "image 162/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31480.jpg: 384x640 (no detections), 94.5ms\n",
      "image 163/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31500.jpg: 384x640 (no detections), 141.8ms\n",
      "image 164/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31520.jpg: 384x640 (no detections), 131.1ms\n",
      "image 165/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31560.jpg: 384x640 1 car, 148.7ms\n",
      "image 166/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31600.jpg: 384x640 2 cars, 150.7ms\n",
      "image 167/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31620.jpg: 384x640 1 car, 141.7ms\n",
      "image 168/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31640.jpg: 384x640 (no detections), 174.9ms\n",
      "image 169/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31660.jpg: 384x640 (no detections), 140.5ms\n",
      "image 170/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31680.jpg: 384x640 (no detections), 126.5ms\n",
      "image 171/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31700.jpg: 384x640 1 car, 118.4ms\n",
      "image 172/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_31720.jpg: 384x640 1 car, 125.8ms\n",
      "image 173/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_400.jpg: 384x640 1 car, 143.4ms\n",
      "image 174/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_420.jpg: 384x640 1 car, 158.0ms\n",
      "image 175/175 C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images\\vid_5_440.jpg: 384x640 1 car, 156.1ms\n",
      "Speed: 1.3ms pre-process, 140.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\exp3\u001b[0m\n",
      "89 labels saved to yolov5\\runs\\detect\\exp3\\labels\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Siddhant\\yolov5\\detect.py --weights C:\\Users\\Siddhant\\yolov5\\runs\\train\\car_detection5\\weights\\best.pt --source C:\\Users\\Siddhant\\Documents\\Python\\Project5\\testing_images --img 640 --conf 0.25 --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6845a-e249-4b4b-aed6-653ff6559c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
